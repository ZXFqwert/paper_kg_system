#!/usr/bin/env python3
"""
è®ºæ–‡çŸ¥è¯†å›¾è°±ç³»ç»Ÿæ¼”ç¤ºè„šæœ¬
"""

import os
import json
import sys

def create_demo_config():
    """åˆ›å»ºæ¼”ç¤ºé…ç½®"""
    config = {
        "openai": {
            "api_base": "https://api.huiyan-ai.cn/v1",
            "api_key": "sk-f9U3GL2EBMrvw524mgkLKqmRrjhdKWi05Bp5u1tAHcAbiSkC",
            "extract_model": "gpt-4.1",
            "qa_model": "gpt-4.1",
            "temperature": 0.1
        },
        "system": {
            "deep_mode": False,
            "max_concurrent_extractions": 3,
            "chunk_size": 1200,
            "chunk_overlap": 100
        },
        "graph": {
            "entity_extract_max_gleaning": 1,
            "entity_summary_to_max_tokens": 500,
            "community_report_max_tokens": 15000
        }
    }
    
    os.makedirs('data', exist_ok=True)
    with open('data/config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print("âœ“ æ¼”ç¤ºé…ç½®å·²åˆ›å»º")

def create_demo_papers():
    """åˆ›å»ºæ¼”ç¤ºè®ºæ–‡æ•°æ®"""
    papers = {
        "2301.00001": {
            "id": "2301.00001",
            "title": "Attention Is All You Need",
            "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar"],
            "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...",
            "published": "2017-06-12T17:59:59Z",
            "categories": ["cs.CL", "cs.AI"],
            "arxiv_url": "http://arxiv.org/abs/1706.03762v5",
            "pdf_url": "http://arxiv.org/pdf/1706.03762v5.pdf",
            "collected_at": "2024-01-01T10:00:00",
            "updated_at": "2024-01-01T10:00:00",
            "deep_mode": False,
            "extracted": False,
            "extraction_status": "pending"
        },
        "2301.00002": {
            "id": "2301.00002", 
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee"],
            "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers...",
            "published": "2018-10-11T18:33:37Z",
            "categories": ["cs.CL"],
            "arxiv_url": "http://arxiv.org/abs/1810.04805v2",
            "pdf_url": "http://arxiv.org/pdf/1810.04805v2.pdf",
            "collected_at": "2024-01-01T10:05:00",
            "updated_at": "2024-01-01T10:05:00",
            "deep_mode": False,
            "extracted": False,
            "extraction_status": "pending"
        }
    }
    
    os.makedirs('data/papers', exist_ok=True)
    with open('data/papers/metadata.json', 'w', encoding='utf-8') as f:
        json.dump(papers, f, indent=2, ensure_ascii=False)
    
    print("âœ“ æ¼”ç¤ºè®ºæ–‡æ•°æ®å·²åˆ›å»º")

def print_usage_guide():
    """æ‰“å°ä½¿ç”¨æŒ‡å—"""
    print("\n" + "="*60)
    print("ğŸ“– è®ºæ–‡çŸ¥è¯†å›¾è°±ç³»ç»Ÿä½¿ç”¨æŒ‡å—")
    print("="*60)
    
    print("\nğŸš€ å¯åŠ¨ç³»ç»Ÿ:")
    print("   python run.py")
    print("   æˆ–è€…: python app.py")
    
    print("\nğŸŒ è®¿é—®åœ°å€:")
    print("   http://localhost:5000")
    
    print("\nâš™ï¸ é¦–æ¬¡ä½¿ç”¨è®¾ç½®:")
    print("   1. è®¿é—®'ç³»ç»Ÿè®¾ç½®'é¡µé¢")
    print("   2. é…ç½®æ‚¨çš„OpenAI API Key")
    print("   3. è®¾ç½®API Base URLï¼ˆå¦‚ä½¿ç”¨ä»£ç†ï¼‰")
    print("   4. ç‚¹å‡»'æµ‹è¯•è¿æ¥'éªŒè¯é…ç½®")
    
    print("\nğŸ“ åŸºæœ¬æµç¨‹:")
    print("   1. è®ºæ–‡æ£€ç´¢ -> è¾“å…¥å…³é”®è¯æœç´¢ArXivè®ºæ–‡")
    print("   2. æ”¶å½•è®ºæ–‡ -> ç‚¹å‡»'æ”¶å½•'ä¿å­˜æ„Ÿå…´è¶£çš„è®ºæ–‡") 
    print("   3. æŠ½å–å®ä½“ -> åœ¨çŸ¥è¯†å›¾è°±é¡µé¢ç‚¹å‡»'æŠ½å–'")
    print("   4. æ„å»ºå›¾è°± -> ç‚¹å‡»'æ„å»ºçŸ¥è¯†å›¾è°±'")
    print("   5. æ™ºèƒ½é—®ç­” -> è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢")
    
    print("\nğŸ’¡ åŠŸèƒ½äº®ç‚¹:")
    print("   â€¢ å®æ—¶æœç´¢ArXivè®ºæ–‡åº“")
    print("   â€¢ è‡ªåŠ¨å®ä½“å…³ç³»æŠ½å–")
    print("   â€¢ Local/Globalä¸¤ç§æŸ¥è¯¢æ¨¡å¼")
    print("   â€¢ è¿›åº¦å®æ—¶åé¦ˆ")
    print("   â€¢ ç°ä»£åŒ–å“åº”å¼ç•Œé¢")
    
    print("\nâš ï¸ æ³¨æ„äº‹é¡¹:")
    print("   â€¢ éœ€è¦æœ‰æ•ˆçš„OpenAI API Key")
    print("   â€¢ ç¡®ä¿ç½‘ç»œå¯è®¿é—®ArXivå’ŒOpenAI")
    print("   â€¢ æŠ½å–å’ŒæŸ¥è¯¢ä¼šæ¶ˆè€—API tokens")
    print("   â€¢ å»ºè®®åœ¨ç¨³å®šç½‘ç»œç¯å¢ƒä¸‹ä½¿ç”¨")
    
    print("\nğŸ“ æ•°æ®å­˜å‚¨:")
    print("   â€¢ data/papers/ - è®ºæ–‡æ•°æ®")
    print("   â€¢ data/graph/ - çŸ¥è¯†å›¾è°±æ•°æ®")
    print("   â€¢ data/config.json - ç³»ç»Ÿé…ç½®")
    
    print("\nğŸ”§ æ•…éšœæ’é™¤:")
    print("   â€¢ æ£€æŸ¥APIé…ç½®æ˜¯å¦æ­£ç¡®")
    print("   â€¢ ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
    print("   â€¢ æŸ¥çœ‹æ§åˆ¶å°é”™è¯¯ä¿¡æ¯")
    print("   â€¢ é‡å¯åº”ç”¨é‡æ–°åŠ è½½é…ç½®")

def main():
    print("ğŸ¯ è®ºæ–‡çŸ¥è¯†å›¾è°±ç³»ç»Ÿæ¼”ç¤ºåˆå§‹åŒ–")
    print("-" * 40)
    
    # æ£€æŸ¥å½“å‰ç›®å½•
    if not os.path.exists('app.py'):
        print("âŒ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
        return
    
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    create_demo_config()
    create_demo_papers()
    
    print("\nâœ… æ¼”ç¤ºç¯å¢ƒåˆå§‹åŒ–å®Œæˆ!")
    
    # æ˜¾ç¤ºä½¿ç”¨æŒ‡å—
    print_usage_guide()
    
    print("\n" + "="*60)
    print("ğŸ“‹ å¿«é€Ÿå¯åŠ¨å‘½ä»¤:")
    print("   python run.py")
    print("="*60)

if __name__ == "__main__":
    main() 